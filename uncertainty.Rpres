<style>

.reveal section img {
  border: 0px;
  box-shadow: 0 0 0 0;
}
.reveal table td {
  border: 0px;
}

.reveal table {
  border: 0px;
}

.reveal h1 {
  font-size: 2em;
}

.reveal h3 {
  font-size: 1.2em;
}

.reveal figcaption {
  font-size: 0.4em;
}

.small-code pre code {
  font-size: 1em;
}

.reveal .smalltext {
  font-size: 0.75em;
}

</style>


Plus/minus what? Let's talk about uncertainty
========================================================
author: Sigrid Keydana, Trivadis
date: 2017/22/11
autosize: true
incremental:false
width: 1400
height: 900


========================================================
type:prompt

&nbsp; 

&nbsp; 

<h1>
In this world nothing can be said to be certain, except death and taxes
</h1>


Welcome to everything else!
========================================================

&nbsp;

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/',
                      echo=FALSE, warning=FALSE, message=FALSE,
                      cache = TRUE)
```

```{r}
library(ggplot2)
library(dplyr)
library(R.matlab)
library(rethinking)
library(ggjoy)
library(forecast)
```


- How many super cool iphone lookalikes will we sell next quarter?
- When should we invest in more powerful servers?
- How many boxes of super healthy energy bars should we keep in stock?
- How long does it take to run this batch job?
- How much time do you need to get me this exposition?


<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />


Our task today: forecast men's 400m Olympic winning times
========================================================

&nbsp;

It's 2000, just before the Olympics. This is the data we have:

```{r}
data <- readMat("olympics.mat")
male400 <- data$male400[ ,1:2]
male400 <- as.data.frame(male400) %>% rename(year = V1, seconds = V2)
male400 <- male400 %>% bind_rows(
  c(year = 2012, seconds = 43.94), c(year = 2016, seconds = 43.03))

# data up till 1996
male400_1996 <- male400 %>% filter(year < 1997)

# data from 2000
male400_2000 <- male400 %>% filter(year > 1997)

bold_text_20 <- element_text(face = "bold", size = 20)
ggplot(male400_1996, aes(x = year, y = seconds)) + geom_line() + ggtitle("Men's 400m Olympic winning times 1986-1996") +
  xlab("year") + ylab("seconds") + 
  theme(title = bold_text_20, axis.title = bold_text_20, axis.text = bold_text_20)


```


&nbsp;

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />


42.3 seconds? 42.1?
========================================================

&nbsp;

Linear regression says 42.33.

Whatever we say, it's pretty likely to be wrong...


<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />


How do we deal with this?
========================================================

&nbsp;

Being frequentists (for now): prediction intervals to the rescue!




<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />



Wait: prediction intervals? 
========================================================
class:small-code

&nbsp;

Wasn't that called "confidence intervals?"

Let's take the example of linear regression to see.


```{r, echo=TRUE}
(fit <- lm(seconds ~ year, male400_1996))
```

&nbsp;

Here's the point prediction:

```{r, echo=TRUE}
fit %>% predict(newdata = data.frame(year = c(2000)))
# or simply
fit$coefficients[1] + fit$coefficients[2] * 2000
```


<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />



Let's try getting those (confidence? prediction?) intervals!
========================================================
class:small-code

&nbsp;

Confidence intervals:

```{r, echo=TRUE}
fit %>% predict(newdata = data.frame(year = c(2000)), interval = "confidence")
```

Prediction intervals:

```{r, echo=TRUE}
fit %>% predict(newdata = data.frame(year = c(2000)), interval = "prediction")
```


Quite a difference! So which one do we take?

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />



One step back: sampling variation and standard errors
========================================================

&nbsp;

- In our example, we are doing one-variable linear regression, which means we estimate an _intercept_ and a _slope_, that together make up the equation of a line:

$y_i = \beta_0 + \beta_1 x_i + \epsilon_i$
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
$\hat \beta_0 = \bar y - \hat \beta_1 \bar x$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
$\hat \beta_1 = cor(y, x) \frac{sd(y)}{sd(x)}$


- These estimates vary depending on the _sample_ they are estimated from
- The statistical method gives us _standard errors_ for these estimates


$\sigma_{\hat \beta_0} = \hat \sigma^2 \left(\frac{1}{n} + \frac{\bar x^2}{\sum_{i=1}^n (x_i - \bar x)^2 }\right)$
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
$\sigma_{\hat \beta_1} = \hat \sigma^2 / \sum_{i=1}^n (x_i - \bar x)^2$
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
with
$\hat \sigma^2 =\frac{1}{n-2}\sum_{i=1}^n e_i^2$

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />



Which let us construct confidence intervals
========================================================
class:small-code

&nbsp;

- for the parameters
- for the line overall

Let's do this manually for the parameters.
A 95% confidence interval for the intercept would look like this:

```{r, echo=TRUE}
intercept_est <- summary(fit)$coefficients[1,1]
intercept_se <- summary(fit)$coefficients[1,2]
(conf_interval <- intercept_est + c(-1, 1) * qt(.975, df = fit$df) * intercept_se)
```

&nbsp;

Same procedure for the slope:

```{r, echo=TRUE}
slope_est <- summary(fit)$coefficients[2,1]
slope_se <- summary(fit)$coefficients[2,2]
(conf_interval <- slope_est + c(-1, 1) * qt(.975, df = fit$df) * slope_se)
```


<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />



Which means we can say
========================================================

&nbsp;

&nbsp;


> 
"with 95% confidence, we estimate that having 4 years pass results in a decrease in the men's 400m Olympic winning times of 0.07 to 0.1 seconds"

&nbsp;

&nbsp;

... which is not yet a confidence interval for the estimated points on the regression line ... 


<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />



A confidence interval for the regression line
========================================================

&nbsp;

We need the standard error for a point $x_0$ on the regression line: &nbsp; &nbsp; &nbsp; &nbsp; $\hat \sigma\sqrt{\frac{1}{n} +  \frac{(x_0 - \bar x)^2}{\sum_{i=1}^n (x_i - \bar x)^2}}$

This reflects the amount of uncertainty due to our estimates being based on _sample variation_.
Uncertainty is smallest near the mean of the predictor ($\bar x$).

```{r, fig.width=16}
df <- male400_1996 %>% bind_cols(is_pred = factor(rep(0, nrow(male400_1996)), levels = c(0,1)))
df <-  df %>% bind_rows(data.frame(year = seq(2000, 2016, by=4), is_pred = factor(rep(1,5), levels = c(0,1))))
preds <- fit %>% predict(newdata = df, interval = "confidence")
df[25:29,2] <- preds[25:29,1]
ggplot(df, aes(x = year, y=seconds)) + geom_point(aes(color = is_pred, shape = is_pred), size = 3) + 
  geom_ribbon(aes(ymin = preds[ , 2], ymax = preds[ , 3]), alpha = 0.2) +
  ggtitle("Men's 400m Olympic winning times 1986-1996 and predictions for 2000-2016") +
  xlab("year") + ylab("seconds") + 
  theme(title = bold_text_20, axis.title = bold_text_20, axis.text = bold_text_20, legend.position = "none")
```

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />



But there's an additional source of uncertainty ...
========================================================

&nbsp;

... due to predictor $x$ (the year we're in) not being 100% accountable for the outcome $y$ (the 400m winning time).

The standard error for an actual prediction is: &nbsp; &nbsp; &nbsp; &nbsp; $\hat \sigma\sqrt{1 + \frac{1}{n} +  \frac{(x_0 - \bar x)^2}{\sum_{i=1}^n (x_i - \bar x)^2}}$


```{r, fig.width=16}
df <- male400_1996 %>% bind_cols(is_pred = factor(rep(0, nrow(male400_1996)), levels = c(0,1)))
df <-  df %>% bind_rows(data.frame(year = seq(2000, 2016, by=4), is_pred = factor(rep(1,5), levels = c(0,1))))
preds <- fit %>% predict(newdata = df, interval = "prediction")
df[25:29,2] <- preds[25:29,1]
ggplot(df, aes(x = year, y=seconds)) + geom_point(aes(color = is_pred, shape = is_pred), size = 3) + 
  geom_ribbon(aes(ymin = preds[ , 2], ymax = preds[ , 3]), alpha = 0.2) +
  ggtitle("Men's 400m Olympic winning times 1986-1996 and predictions for 2000-2016") +
  xlab("year") + ylab("seconds") + 
  theme(title = bold_text_20, axis.title = bold_text_20, axis.text = bold_text_20, legend.position = "none")
```



<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

Fine, but... that's all specific to linear regression...
========================================================

&nbsp;

- What if we were using, say, ARIMA for forecasting that time series?

- What if we used some custom method that does not come with standard errors / confidence intervals already?


<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />



Let's try ARIMA on the 400m winning times!
========================================================
class:small-code


&nbsp;

```{r, echo=TRUE}
fit <- auto.arima(male400_1996$seconds, allowdrift = FALSE)
fit$coef
```

&nbsp;

We get standard errors for the parameter estimations:

```{r, echo=TRUE}
sqrt(diag(vcov(fit)))
```


<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />



ARIMA prediction intervals
========================================================
class:small-code

&nbsp;

... which means we can get prediction intervals here, too:

```{r, fig.width=16}
autoplot(forecast(fit, h=5))
```


<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />




So we were in luck...
========================================================

&nbsp;

What can we do when we're not magically given those precision intervals?

&nbsp;

We'll probably need to pull ourselves up by our own bootstraps...

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />



The bootstrap
========================================================

&nbsp;

- Ideally, we'd compute a parameter's standard error from many repeated samples
- Unfortunately, most of the time we just have one
- Idea: create synthetical samples from the original sample, using _sampling with replacement_

<figure>
    <img src='bootstrap.png' width='40%'/>
    <figcaption>Source: [1]</figcaption>
</figure>

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />




So many ways... anything we could do to make this more intuitive?
========================================================

&nbsp;

A better match for our intuitions in several ways...

- data is given, parameters are random (and thus have distributions, too!)
- as new data comes in, we update our expectations - according to famous _Bayes theorem_

$$P(A ~|~ B) = \frac{P(B|A) * P(A)}{P(B)}$$ 


<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />




========================================================

&nbsp;



<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />




========================================================

&nbsp;



<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />




========================================================

&nbsp;



<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />




========================================================

&nbsp;



<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />




========================================================

&nbsp;



<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />




========================================================

&nbsp;



<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />




========================================================

&nbsp;



<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />




========================================================

&nbsp;



<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />




========================================================

&nbsp;



<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />



##############################################################################################

TBD 

- bootstrap??
- bayes
- time series??
- dropout
- end with real values 


Sources
========================================================
class:smalltext

[] 

